# ğŸ§  GenAI SQL Tools Suite

A production-ready suite of modular, asynchronous tools for analyzing, refactoring, commenting, and auditing SQL code using Azure OpenAI (GPT-4o).

> Designed with **security**, **performance**, **auditability**, and **HIPAA/HITECH compliance** in mind.

---

## ğŸ“ Project Structure

```
sql_tools/
â”œâ”€â”€ app.py                      # CLI interface and controller
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ core/                       # Framework and shared logic
â”‚   â”œâ”€â”€ base_ai_client.py       # Async Azure OpenAI client
â”‚   â”œâ”€â”€ config_loader.py        # Configuration loader (mirrors original config.py)
â”‚   â”œâ”€â”€ logger.py               # HIPAA-compliant logging utility
â”‚   â””â”€â”€ sql_task_base.py        # Abstract base class for GenAI SQL tasks
â”œâ”€â”€ tasks/                      # Modular GenAI SQL task classes
â”‚   â”œâ”€â”€ sql_analyzer.py
â”‚   â”œâ”€â”€ sql_commenter.py
â”‚   â”œâ”€â”€ sql_data_masker.py
â”‚   â”œâ”€â”€ sql_refactorer.py
â”‚   â”œâ”€â”€ sql_explainer.py
â”‚   â”œâ”€â”€ sql_security_auditor.py
â”‚   â”œâ”€â”€ sql_test_generator.py
â”‚   â”œâ”€â”€ sql_performance_benchmark.py  # New: Added performance benchmarking and optimization
â”‚   â”œâ”€â”€ sql_data_masker.py           # New: Data masking and anonymization
â”‚   â”œâ”€â”€ sql_visualizer.py            # New: Visualization and insights
â”‚   â”œâ”€â”€ sql_error_corrector.py       # New: Error correction and debugging
â”‚   â”œâ”€â”€ sql_style_enforcer.py        # New: Style guide enforcement
â”‚   â”œâ”€â”€ natural_language_to_sql.py   # New: Natural language to SQL conversion
â”œâ”€â”€ prompts/                    # Centralized prompt management
â”‚   â”œâ”€â”€ index.yaml              # YAML file defining all prompts and metadata
â”‚   â”œâ”€â”€ summarization/          # Summarization-related prompt templates
â”‚   â”œâ”€â”€ classification/         # Classification-related prompt templates
â””â”€â”€ utils/
    â”œâ”€â”€ file_utils.py           # File I/O, backup, and directory handling
    â”œâ”€â”€ prompt_manager.py       # Centralized prompt loading and validation
    â”œâ”€â”€ sanitizer.py            # LLM output cleaner (markdown, GPT comments)
    â”œâ”€â”€ dynamic_sql_detector.py # New: Utility for dynamic SQL detection
```

---

## âœ… Features

- ğŸ§¹ Data Masking and Anonymization - Automatically masks sensitive data such as emails, phone numbers, credit card numbers, and SSNs.
- âš™ï¸ Modular task engine (comment, analyze, refactor, audit, explain, test)
- ğŸ” Query Simulation and Validation
- ğŸ“‹ Centralized prompt management via `prompts/index.yaml`
- âš¡ Asynchronous OpenAI integration using `httpx`
- ğŸ§¼ Sanitized output with `--sanitize`
- ğŸ” Directory recursion and batching with `--recursive`
- ğŸ§ª Preview results before modifying files with `--dry-run`
- ğŸ” Backup and HIPAA-safe logging
- ğŸ”€ Git integration: auto-stage files with `--git`
- ğŸ“¤ Export to separate files using `--output`
- ğŸŒ Support for multiple SQL dialects using nl_to_sql task (e.g., T-SQL, PostgreSQL, Oracle)
- ğŸš€ Natural Language to SQL Conversion
- ğŸ” Enhanced security audits with SQL injection and role misuse detection
- ğŸ“Š Performance benchmarking and optimization
- ğŸ”§ Data masking and anonymization
- ğŸ¨ SQL Style Guide Enforcement
- ğŸ›  Dynamic SQL Detection
- ğŸ§‘â€ğŸ« SQL Education Mode (Interactive Tutorials)

---

## ğŸ§ª CLI Usage

## ğŸ”’ Mask Sensitive Data in SQL Queries

```bash
python app.py --task=mask --path=example.sql --output=masked_example.sql
```

### ğŸ” What It Does:
- **Task**: `mask` â€” Automatically identifies and masks sensitive data such as:
  - Email addresses.
  - Phone numbers.
  - Credit card numbers.
  - Social Security Numbers (SSNs).
- **`--output=...`**: Writes the masked SQL to a new file.

### ğŸ”§ Enforce SQL Style Guide
```bash
python app.py --task=style_enforce --path=example.sql --sql_dialect=PostgreSQL --output=styled_example.sql
```

### What It Does:
- **Task**: `style_enforce` â€” Enforces SQL coding standards dynamically using AI.
- **`--sql_dialect=...`**: Specifies the SQL dialect (e.g., PostgreSQL, T-SQL).
- **`--output=...`**: Writes the styled SQL to a new file.

### ğŸ”§ Comment a SQL file
```bash
python app.py --task=comment --path=example.sql
```

### ğŸ§¼ Clean and save to new file
```bash
python app.py --task=comment --path=example.sql --sanitize --output=cleaned_example.sql
```

### ğŸ” Preview refactored query (no overwrite)
```bash
python app.py --task=refactor --path=query.sql --dry-run
```

### ğŸ—ƒï¸ Process all .sql files in folder (with backups)
```bash
python app.py --task=analyze --path=./sql_scripts --recursive --backup
```

### ğŸ” Run security audit and stage for Git
```bash
python app.py --task=audit --path=query.sql --git
```

### ğŸ§ª Generate SQL test cases
```bash
python app.py --task=test --path=example.sql --dry-run
```

### ğŸš€ Natural Language to SQL Conversion (inline query)
```bash
python app.py --task=nl_to_sql --path="list all patients diagnosed with diabetes last month" --sql_dialect="PostgreSQL" --schema_path="schema/schema.json" --dry-run
```

### ğŸš€ Natural Language to SQL Conversion (query file)
```bash
python app.py --task=nl_to_sql --path=queries/nl_query.txt --sql_dialect="T-SQL" --schema_path="schema/HealthClaimsDW.json" --output=output/generated_query.sql
```

### ğŸ“Š Benchmark SQL query performance
```bash
python app.py --task=benchmark --path=example.sql --dry-run
```

### ğŸ“ˆ Visualize query execution plan
```bash
python app.py --task=visualize --path=example.sql
```

### ğŸ” Dynamic SQL Detection

Detect dynamic SQL patterns and analyze risks/optimizations:

#### Analyze risks and optimizations - Detect patterns only:
```bash
python app.py --task=dynamic_sql --path="queries/sample_query.sql" --detect_only --dry-run
```

#### Process all SQL files in a directory recursively:

```bash
python app.py --task=dynamic_sql --path="queries/" --recursive
```

---

## ğŸ›  Configuration

Edit `core/config_loader.py` to match your Azure OpenAI deployment:

```python
AOPAI_KEY = "your-api-key"
API_BASE = "https://your-resource.openai.azure.com/"
AOPAI_API_VERSION = "2025-01-01-preview"
AOPAI_DEPLOY_MODEL = "gpt-4o-dev"
```

---

## ğŸ“¦ Install Requirements

```bash
pip install -r requirements.txt
```

---

## ğŸ“‹ Centralized Prompt Management

All prompts are defined in a single `index.yaml` file, which maps specific tasks to their associated prompt templates. This design enables:

- Consistent prompt formatting
- Easier version control and auditing
- Reusability across multiple modules

Each task class dynamically loads its associated prompt using metadata from this file.

### ğŸ§¾ Example `index.yaml` Entry

```yaml
commenter.add_comments:
  inline: |
    "You are a T-SQL expert. Given the SQL code below, please:
    1. Prepend a comment header block with:
       -- =============================================
       -- Author:      {user}
       -- Create date: {timestamp}
       -- Description: <Provide a detailed overview of this query>
       -- =============================================

    2. Add or improve inline comments throughout the query.
    3. Only return the updated SQL code with no markdown formatting.

    SQL Code:
    {sql_query}"
  used_by: tasks.sql_commenter.SQLCommenter
  inputs:
    - sql_query
    - user
    - timestamp
  version: 1.0
  description: Add comments and metadata headers to SQL queries.
```

---

## ğŸ” Security & Compliance

- Logs are stored per task under the `logs/` directory
- Safe use of T-SQL comments (`--`, `/* ... */`)
- Output sanitized for code-only results when using `--sanitize`
- Aligned with HIPAA/HITECH compliance standards

---

## ğŸ“„ License

This project is licensed under the [MIT License](./LICENSE).

---

## ğŸ¤ Contributing

- Fork and open a PR
- Follow modular design and SOLID principles
- Ensure proper logging, error handling, and secure configuration

---

## ğŸ™Œ Authors & Acknowledgments

- Vision and engineering by **Hans Esquivel**
- Powered by **Azure OpenAI**
- Thanks to the SQL and ML community for insights and best practices
---
